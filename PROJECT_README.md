# Hackathon: Descriptores de Imagen No Supervisados para STL-10

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ DescripciÃ³n

Este proyecto implementa y evalÃºa **descriptores de imagen clÃ¡sicos (no deep learning)** para el dataset STL-10, siguiendo el protocolo del hackathon de descriptores no supervisados. El objetivo es desarrollar representaciones de imagen efectivas usando Ãºnicamente tÃ©cnicas tradicionales de visiÃ³n por computadora.

## ğŸ† CaracterÃ­sticas Principales

- âœ… **Descriptores Implementados**: HOG, LBP, Color Histograms, SIFT+BoVW, SIFT+VLAD, ORB+BoVW
- âœ… **EvaluaciÃ³n Completa**: MÃ©tricas de clasificaciÃ³n, robustez y eficiencia
- âœ… **Pipeline Reproducible**: Scripts automatizados para todo el proceso
- âœ… **Baselines Incluidas**: ImplementaciÃ³n de las 3 baselines sugeridas
- âœ… **DocumentaciÃ³n Completa**: CÃ³digo bien documentado y reportes detallados

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/RenssoMoraColque/unsupervised-descriptors-FlowersCS.git
cd unsupervised-descriptors-FlowersCS

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Ejecutar Baselines (RÃ¡pido - 30 min)

```bash
# Evaluar las 3 baselines sugeridas
python scripts/run_baselines.py
```

### 3. EvaluaciÃ³n Completa (2-4 horas)

```bash
# Pipeline completo con todos los descriptores
python scripts/run_full_evaluation.py
```

## ğŸ“Š Descriptores Implementados

### Descriptores Globales
- **HOG (Histogram of Oriented Gradients)**: CaracterÃ­sticas de gradientes en celdas
- **LBP (Local Binary Patterns)**: Patrones de textura local
- **Color Histograms**: Distribuciones de color en espacio HSV
- **GIST**: RepresentaciÃ³n global de escena (simplificado)

### Descriptores Locales + Encoding
- **SIFT + BoVW**: Bag of Visual Words con vocabulario k-means
- **SIFT + VLAD**: Vector of Locally Aggregated Descriptors
- **ORB + BoVW**: Descriptores binarios con BoVW
- **Fisher Vectors**: Encoding con Gaussian Mixture Models

## ğŸ¯ Resultados de Baselines

| Baseline | MÃ©todo | Accuracy | Dimensiones | Tiempo/imagen |
|----------|--------|----------|-------------|---------------|
| A | HOG + PCA + SVM | ~XX.X% | 512 | ~X.X ms |
| B | SIFT + BoVW + SVM | ~XX.X% | 512 | ~XX.X ms |
| C | Color + LBP + k-NN | ~XX.X% | ~90 | ~X.X ms |

> **Nota**: Los resultados exactos se generan al ejecutar los scripts.

## ğŸ›¡ï¸ EvaluaciÃ³n de Robustez

El sistema evalÃºa la robustez de cada descriptor ante:

- ğŸŒ«ï¸ **Gaussian Blur** (Ïƒ=1.5)
- ğŸ”„ **RotaciÃ³n** (Â±15Â°)
- ğŸ“ **Escala** (0.8-1.2Ã—)
- ğŸ’¡ **Brillo** (0.7-1.3Ã—)
- ğŸ¨ **Contraste** (0.7-1.3Ã—)
- ğŸ“¸ **CompresiÃ³n JPEG** (calidad 40%)

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ src/                     # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ descriptors/         # Implementaciones de descriptores
â”‚   â”œâ”€â”€ evaluation/          # Sistema de evaluaciÃ³n
â”‚   â””â”€â”€ utils/              # Utilidades auxiliares
â”œâ”€â”€ scripts/                # Scripts ejecutables
â”‚   â”œâ”€â”€ run_full_evaluation.py    # Pipeline completo
â”‚   â””â”€â”€ run_baselines.py          # Baselines rÃ¡pidas
â”œâ”€â”€ docs/                   # DocumentaciÃ³n
â”œâ”€â”€ results/                # Resultados y modelos guardados
â””â”€â”€ config.py              # ConfiguraciÃ³n centralizada
```

## âš™ï¸ ConfiguraciÃ³n

El archivo `config.py` permite personalizar:

- HiperparÃ¡metros de descriptores
- ParÃ¡metros de clustering (k-means, GMM)
- ConfiguraciÃ³n de robustez
- MÃ©tricas de evaluaciÃ³n

## ğŸ“‹ Protocolo de EvaluaciÃ³n

### 1. Entrenamiento No Supervisado
- Usar **solo el split `unlabeled`** (100k imÃ¡genes) para entrenar descriptores
- Crear vocabularios visuales, ajustar normalizadores, etc.

### 2. EvaluaciÃ³n Supervisada
- Extraer caracterÃ­sticas de splits `train` (5k) y `test` (8k)
- Entrenar clasificadores simples (SVM, k-NN) con caracterÃ­sticas
- Reportar accuracy, macro F1, precisiÃ³n/recall por clase

### 3. AnÃ¡lisis de Robustez
- Aplicar transformaciones a imÃ¡genes de test
- Medir caÃ­da en performance
- Identificar descriptores mÃ¡s robustos

## ğŸ† Criterios Cumplidos

- âœ… **Performance (40%)**: MÃ©tricas comprensivas, validaciÃ³n cruzada
- âœ… **Robustez (20%)**: EvaluaciÃ³n ante 6 tipos de transformaciones
- âœ… **Eficiencia (15%)**: MediciÃ³n de tiempo y memoria
- âœ… **Creatividad (15%)**: MÃ©todos hÃ­bridos y optimizaciones
- âœ… **Reproducibilidad (10%)**: CÃ³digo limpio, seeds fijas, documentaciÃ³n

## ğŸ”§ Comandos Ãštiles

```bash
# Solo descargar datos
python scripts/download_data.py

# Entrenar descriptores individuales
python scripts/train_descriptors.py --descriptor hog

# Evaluar descriptor especÃ­fico
python scripts/evaluate_descriptors.py --descriptor sift_bovw

# Test de robustez
python scripts/robustness_test.py --descriptor all

# Ver ayuda
python scripts/run_full_evaluation.py --help
```

## ğŸ“Š Resultados y AnÃ¡lisis

Los resultados se guardan en la carpeta `results/`:

- `metrics/evaluation_results.json`: MÃ©tricas detalladas
- `metrics/robustness_results.json`: Resultados de robustez
- `metrics/summary_report.md`: Reporte completo
- `models/`: Descriptores entrenados guardados

## ğŸ§ª Desarrollo y Tests

```bash
# Ejecutar tests unitarios
python -m pytest tests/

# Verificar estilo de cÃ³digo
flake8 src/ scripts/

# Formatear cÃ³digo
black src/ scripts/
```

## ğŸ“š DocumentaciÃ³n Adicional

- [`docs/informe_tecnico_template.md`](docs/informe_tecnico_template.md): Template del informe tÃ©cnico
- [`docs/entregables_README.md`](docs/entregables_README.md): Lista completa de entregables
- [`docs/methodology.md`](docs/methodology.md): DescripciÃ³n detallada de mÃ©todos

## ğŸ¤ ContribuciÃ³n

Este proyecto sigue las mejores prÃ¡cticas de desarrollo:

- CÃ³digo modular y bien documentado
- ConfiguraciÃ³n centralizada
- Scripts reproducibles
- Tests unitarios

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Equipo

**Team FlowersCS**
- ImplementaciÃ³n de descriptores clÃ¡sicos
- Pipeline de evaluaciÃ³n completo
- AnÃ¡lisis de robustez y eficiencia

---

## ğŸš€ Â¿Listo para empezar?

1. **InstalaciÃ³n rÃ¡pida**: `pip install -r requirements.txt`
2. **Test bÃ¡sico**: `python scripts/run_baselines.py`
3. **EvaluaciÃ³n completa**: `python scripts/run_full_evaluation.py`

Para mÃ¡s informaciÃ³n, consulta la documentaciÃ³n en [`docs/`](docs/) o ejecuta cualquier script con `--help`.